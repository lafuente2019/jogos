# ğŸš€ Projeto GCP - Pipeline de Dados

## SumÃ¡rio
- [VisÃ£o Geral](#visÃ£o-geral)
- [Contexto do NegÃ³cio](#contexto-do-negÃ³cio)
- [Arquitetura da SoluÃ§Ã£o](#arquitetura-da-soluÃ§Ã£o)
- [Camadas de Dados](#camadas-de-dados)
- [Componentes GCP Utilizados](#componentes-gcp-utilizados)
- [ExecuÃ§Ã£o e OrquestraÃ§Ã£o](#execuÃ§Ã£o-e-orquestraÃ§Ã£o)
- [GovernanÃ§a e SeguranÃ§a](#governanÃ§a-e-seguranÃ§a)
- [Scripts e PadrÃµes](#scripts-e-padrÃµes)
- [Monitoramento e Logs](#monitoramento-e-logs)
- [Como Executar Manualmente](#como-executar-manualmente)
- [Como Contribuir](#como-contribuir)
- [LicenÃ§a](#licenÃ§a)
- [Contato](#contato)

---

## VisÃ£o Geral
Este projeto implementa um pipeline completo na **Google Cloud Platform (GCP)** para ingestÃ£o, processamento, validaÃ§Ã£o e carga de dados analÃ­ticos, permitindo criar uma base consolidada para geraÃ§Ã£o de relatÃ³rios e dashboards.

---

## Contexto do NegÃ³cio
Muitas empresas precisam monitorar, transformar e disponibilizar dados de diferentes fontes para anÃ¡lises estratÃ©gicas. Este pipeline resolve:

- Centralizar dados em um **Data Lakehouse (BigQuery)**.
- Automatizar tarefas repetitivas, como ingestÃ£o e tratamento de arquivos.
- Garantir dados prontos para anÃ¡lises em tempo hÃ¡bil, reduzindo custo operacional.

---

## Arquitetura da SoluÃ§Ã£o
```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Fonte de Dados          â”‚
â”‚ (CSV, Parquet, JSON, API)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Cloud Storage (GCS)      â”‚
â”‚ - lnd/ : camada landing      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Dataproc (Spark)      â”‚
â”‚ - TransformaÃ§Ã£o e limpeza    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BigQuery             â”‚
â”‚ - raw.dataset.tables         â”‚
â”‚ - prep.dataset.tables        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Data Studio / Looker     â”‚
â”‚    Dashboards e relatÃ³rios   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ExecuÃ§Ã£o Manual
Exemplo de payload JSON para publicar manualmente no tÃ³pico Pub/Sub:


{
  "project_id": "seu-projeto-gcp",
  "region": "us-central1",
  "workflow_template": "pipeline-transform",
  "parameters": {
    "DELTA_DAY": "D-1",
    "DATA_INICIO": "2025-07-01",
    "DATA_FIM": "2025-07-10",
    "RUN_LIST": "step1,step2,step3"
  }
}


GovernanÃ§a e SeguranÃ§a
Uso de Service Accounts especÃ­ficas, com papÃ©is restritos, seguindo o princÃ­pio do menor privilÃ©gio.

Dados criptografados em trÃ¢nsito (TLS) e em repouso.

Auditoria completa via Cloud Audit Logs.

Scripts e PadrÃµes
Scripts Spark desenvolvidos em PySpark, versionados neste repositÃ³rio.

PadrÃµes de nomenclatura:

Buckets: projeto-solucao-lnd-<ambiente>

Datasets: raw_<projeto>, prep_<projeto>

Tabelas: tb_<entidade>_<detalhe>

Monitoramento e Logs
Stackdriver Logging centraliza logs do Dataproc, Functions e Scheduler.

BigQuery Audit Logs para rastrear quem acessou ou modificou datasets.

Alertas configurados para falhas crÃ­ticas ou uso anÃ´malo de recursos.

Como Executar Manualmente
PublicaÃ§Ã£o de mensagem diretamente pelo terminal com gcloud:


gcloud pubsub topics publish foundation-start-dataproc-workflow \
  --message='{
    "project_id":"seu-projeto-gcp",
    "region":"us-central1",
    "workflow_template":"pipeline-transform",
    "parameters":{
      "DELTA_DAY":"D-1",
      "DATA_INICIO":"2025-07-01",
      "DATA_FIM":"2025-07-10",
      "RUN_LIST":"step1,step2"
    }
  }'



Como Contribuir
Clone o repositÃ³rio:


git clone https://github.com/sua-org/seu-projeto-gcp.git
Crie uma branch para suas alteraÃ§Ãµes:


git checkout -b feature/minha-nova-feature
Realize commits e envie seu Pull Request.

LicenÃ§a
Este projeto Ã© licenciado sob a licenÃ§a MIT. Para mais detalhes, consulte o arquivo LICENSE.

Contato
Nome	FunÃ§Ã£o	Contato
Valter Lafuente	Data Engineer / Owner	valter.lafuente@exemplo.com
Equipe Analytics	Suporte TÃ©cnico	analytics@empresa.com.br

